# Обучение нейронных сетей с математической точки зрения

## Forward & backward pass в нейронных сетях (автор: Азат Валеев)

*Данный параграф является кратким пересказом [соответствующей главы](https://education.yandex.ru/handbook/ml/article/metod-obratnogo-rasprostraneniya-oshibki) из ml-handbook от ШАДа, оттуда же позаимствованы медиа материалы, для более детального погружения читателям советуется обращаться к ней.*

Традиционно для обучения нейронных сетей используют градиентные методы оптимизации, а для их применения необходимо уметь эффективно вычислять градиенты функции потерь по обучающимся параметрам. 

Для этого применяется алгоритм обратного распространения ошибки (back propagation), суть которого вытекает из формулы вычисления производной сложной функции: если $f(w_0) = g_m(g_{m-1}(\ldots g_1(w_0)\ldots))$ (в качестве примера возьмём одномерный случай, переменная $w_0$ -- скаляр, все функции $g_i$ -- скалярные), то $f'(w_0) = g_m'(g_{m-1}(\ldots g_1(w_0)\ldots))\cdot g'_{m-1}(g_{m-2}(\ldots g_1(w_0)\ldots))\cdot\ldots \cdot g'_1(w_0)$. 

Как видно из формулы, для того, чтобы посчитать производную $f'(w_0)$ за один проход, достаточно посчитать промежуточные значения функции $g_1(w_0), g_2(g_1(w_0)),\ldots,g_{m-1}(\ldots g_1(w_0)\ldots)$ и:

* взять производную $g_m$ в точке $g_{m-1}(\ldots g_1(w_0)\ldots)$;

* умножить на производную $g_{m-1}$ в точке $g_{m-2}(\ldots g_1(w_0)\ldots)$;

* и так далее, пока не дойдём до производной $g_1$ в точке $w_0$.

В нейронных сетях алгоритм обратного распространения ошибки формулируется в терминах двух фаз: прямой проход (forward pass) и обратный проход (backward pass):

* Forward pass: вычисляем выход модели по входу, подсчитываем значение функции потерь, при этом для каждого слоя запоминаем его вход (вход промежуточного слоя также часто называется **активацией**).

    ![Forward pass](./assets/forward_pass.png)

    На картинке представлен forward pass для некоторой нейронной сети, сохраненные активации показаны в верхней части рисунка.

* Backward pass: подсчитываем градиенты функции потерь по входу/обучаемым весам слоёв, начиная с самого последнего слоя и двигаясь к самому первому. При этом для вычисления градиентов очередного слоя применяются градиенты следующих слоёв, чьим входом был выход данного слоя, и активации данного слоя.

    ![Backward pass](./assets/backward_pass.gif)

    На анимации представлен backward pass для всё той же нейронной сети, вычисление градиентов поиллюстрировано в нижней её части. 

## SGD и прочие оптимизаторы (автор: Александра Павлова)

## Анализ памяти для наивного шага обучения (автор: Азат Валеев)

Обсудим потребление памяти, которая необходима для реализации наивного шага обучения нейронной сети с использованием back propagation (наивного в том смысле, что пока не будут применяться никакие оптимизации, связанные с памятью). Также в рамках этого параграфа:

* ещё не предполагается природа памяти -- можно думать о том, что мы взаимодействуем с RAM;
* предполагается, что тип данных, в котором хранятся различные числа, выполняются вычисления, -- single-precision floating-point format, более известный как float32 или fp32, занимающий 32 бита или 4 байта памяти. Именно такой тип по умолчанию используется для вещественных чисел во фреймворке `pytorch`. Так что для простоты записей необходимое домножение на константу будет опущено и будет применено только в самом конце подсчетов.

Первоначально, для обучения нейронной сети её веса необходимо разместить в памяти -- для этого нам необходимо {количество весов модели} памяти.

Далее -- forward pass, в процессе вычисления которого запоминаются активации. Под конец выполнения в памяти лежат веса модели + все посчитанные активации.

Затем -- backward pass. При обратном проходе необходимо выделить место под градиенты весов модели, которые по размеру в памяти эквиваленты самим веса модели. Поскольку, вообще говоря, каждая активация может быть необходима для подсчета градиентов первых слоёв, память под активации мы не можем высвобождать (к тому же, эту память можно переиспользовать для следующих шагов обучения). Таким образом, после окончания подсчёта градиентов в памяти лежат веса модели + все посчитанные активации + все градиенты весов.

Для подсчета памяти при применении оптимизационного алгоритма необходимо учитывать, хранит ли алгоритм статистики градиентов для обновления весов. 

Так, например, ванильный SGD не применяет статистики, поэтому ему не нужна дополнительная память. А оптимизатору Adam нужно хранить скользящее среднее предыдущих градиентов и скользящее среднее квадратов элементов градиентов, обе статистики по размерам эквивалентны размеру градиентов модели, который как уже упоминалось эквивалентен размеру весов модели. 

Так что если мы рассмотрим Adam в качемстве стандартного оптимизиатора, то в памяти лежат $\approx$ веса модели + все посчитанные активации + все градиенты весов + 2 * все градиенты весов.

После первого шага обучения потребление памяти остается на том же уровне, поскольку не добавляется ничего нового и успешно переиспользуется ранняя выделенная память (в предположении, что размер батча зафиксирован).

Таким образом, собирая всё вместе, с использованием Adam необходимо $\approx$ веса модели + все посчитанные активации + все градиенты весов + 2 * все градиенты весов = 4 * веса модели + все посчитанные активации памяти; в терминах типа данных fp32 нам нужно  4 байта * (4 * количество параметров модели + количество элементов в активациях).

# Оптимизации

## Модификации оптимизатора по памяти: Adafactor, 8-bit Adam (автор: Александра Павлова)

## Gradient Accumulation (автор: Азат Валеев)

## Activation Checkpointing (автор: Азат Валеев)

## Mixed Precision Training (автор: Георгий Ангени)

Часто встречающимися типами значений для представления нейронных моделей в памяти являются FP32 и FP16 – форматы значений с плавающей точкой, занимающие в памяти 4 и 2 байта соответственно. Ясно, что использование FP16 вместо FP32 позволит уменьшить объем памяти, занимаемый моделью, и увеличить скорость ее обучения, но оно также приведет к ограничению точности параметров, которые модель сможет выучить.

Ниже проиллюстрированы представления FP32 и FP16 в памяти: $S$ – бит знака, $M$ – мантисса (часть числа с плавающей точкой) в двоичном виде, которая умножается на $2^E$, где $E$ – экспонента, представляющая собой целое число в двоичном виде.

![Bitwise representation](assets/mixed_precision_1.png)

В Mixed Precision Training в процессе обучения для весов, значений активации и градиентов используется формат FP16, но сама модель, или ее так называемые master weights, хранятся в FP32. Соответственно, веса, используемые при обучении, получаются именно путем конвертации master weights в FP16.

![Mixed Precision Training](assets/mixed_precision_2.png)

Почему же мы не храним все веса модели в FP16 изначально? Заметим, что разница между экспонентами двух чисел в FP16 (так же, как и в FP32) на единицу соответствует битовому сдвигу мантиссы. Это в сущности означает, что при складывании двух чисел в FP16, отличающихся друг от друга в $2048$ раз (число $2^11$, которое приведет к битовому сдвигу на 11 бит) меньшее число будет обращено в ноль, что сильно скажется на потенциальной точности, которую могут достичь параметры модели при обучении.

Также для того, чтобы значения градиентов в FP16 при обратном проходе не были приравнены к нулю, значение функции потерь искусственно увеличивается в несколько раз и обратное преобразование осуществляется сразу после backward pass (операция называется loss scaling) для того, чтобы не пришлось изменять ранее подобранные гиперпараметры, связанные с градиентами, такие как gradient clipping threshold. На изображении ниже показано распределение изменения весов модели на одной итерации обучения и видно, что без loss scaling все обновления левее красной полосы будут обращены в ноль. Увеличение значения функции потерь даже в 8 раз приведет к тому, что будет учтено сильно больше обновлений и модель обучится лучше.

![Mixed Precision Training](assets/mixed_precision_3.png)
