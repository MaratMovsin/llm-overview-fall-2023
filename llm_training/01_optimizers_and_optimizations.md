# Обучение нейронных сетей с математической точки зрения

## Forward & backward pass в нейронных сетях (автор: Азат Валеев)

*Данный параграф является кратким пересказом [соответствующей главы](https://education.yandex.ru/handbook/ml/article/metod-obratnogo-rasprostraneniya-oshibki) из ml-handbook от ШАДа, оттуда же позаимствованы медиа материалы, для более детального погружения читателям советуется обращаться к ней.*

Традиционно для обучения нейронных сетей используют градиентные методы оптимизации, а для их применения необходимо уметь эффективно вычислять градиенты функции потерь по обучающимся параметрам. 

Для этого применяется алгоритм обратного распространения ошибки (back propagation), суть которого вытекает из формулы вычисления производной сложной функции: если $f(w_0) = g_m(g_{m-1}(\ldots g_1(w_0)\ldots))$ (в качестве примера возьмём одномерный случай, переменная $w_0$ -- скаляр, все функции $g_i$ -- скалярные), то $f'(w_0) = g_m'(g_{m-1}(\ldots g_1(w_0)\ldots))\cdot g'_{m-1}(g_{m-2}(\ldots g_1(w_0)\ldots))\cdot\ldots \cdot g'_1(w_0)$. 

Как видно из формулы, для того, чтобы посчитать производную $f'(w_0)$ за один проход, достаточно посчитать промежуточные значения функции $g_1(w_0), g_2(g_1(w_0)),\ldots,g_{m-1}(\ldots g_1(w_0)\ldots)$ и:

* взять производную $g_m$ в точке $g_{m-1}(\ldots g_1(w_0)\ldots)$;

* умножить на производную $g_{m-1}$ в точке $g_{m-2}(\ldots g_1(w_0)\ldots)$;

* и так далее, пока не дойдём до производной $g_1$ в точке $w_0$.

В нейронных сетях алгоритм обратного распространения ошибки формулируется в терминах двух фаз: прямой проход (forward pass) и обратный проход (backward pass):

* Forward pass: вычисляем выход модели по входу, подсчитываем значение функции потерь, при этом для каждого слоя запоминаем его вход (вход промежуточного слоя также часто называется **активацией**).

    ![Forward pass](./assets/forward_pass.png)

    На картинке представлен forward pass для некоторой нейронной сети, сохраненные активации показаны в верхней части рисунка.

* Backward pass: подсчитываем градиенты функции потерь по входу/обучаемым весам слоёв, начиная с самого последнего слоя и двигаясь к самому первому. При этом для вычисления градиентов очередного слоя применяются градиенты следующих слоёв, чьим входом был выход данного слоя, и активации данного слоя.

    ![Backward pass](./assets/backward_pass.gif)

    На анимации представлен backward pass для всё той же нейронной сети, вычисление градиентов поиллюстрировано в нижней её части. 

## SGD и прочие оптимизаторы (автор: Александра Павлова)

## Анализ памяти для наивного шага обучения (автор: Азат Валеев)

Обсудим потребление памяти, которая необходима для реализации наивного шага обучения нейронной сети с использованием back propagation (наивного в том смысле, что пока не будут применяться никакие оптимизации, связанные с памятью). Также в рамках этого параграфа:

* ещё не предполагается природа памяти -- можно думать о том, что мы взаимодействуем с RAM;
* предполагается, что тип данных, в котором хранятся различные числа, выполняются вычисления, -- single-precision floating-point format, более известный как float32 или fp32, занимающий 32 бита или 4 байта памяти. Именно такой тип по умолчанию используется для вещественных чисел во фреймворке `pytorch`. Так что для простоты записей необходимое домножение на константу будет опущено и будет применено только в самом конце подсчетов.

Первоначально, для обучения нейронной сети её веса необходимо разместить в памяти -- для этого нам необходимо {количество весов модели} памяти.

Далее -- forward pass, в процессе вычисления которого запоминаются активации. Под конец выполнения в памяти лежат веса модели + все посчитанные активации.

Затем -- backward pass. При обратном проходе необходимо выделить место под градиенты весов модели, которые по размеру в памяти эквиваленты самим веса модели. Поскольку, вообще говоря, каждая активация может быть необходима для подсчета градиентов первых слоёв, память под активации мы не можем высвобождать (к тому же, эту память можно переиспользовать для следующих шагов обучения). Таким образом, после окончания подсчёта градиентов в памяти лежат веса модели + все посчитанные активации + все градиенты весов.

Для подсчета памяти при применении оптимизационного алгоритма необходимо учитывать, хранит ли алгоритм статистики градиентов для обновления весов. 

Так, например, ванильный SGD не применяет статистики, поэтому ему не нужна дополнительная память. А оптимизатору Adam нужно хранить скользящее среднее предыдущих градиентов и скользящее среднее квадратов элементов градиентов, обе статистики по размерам эквивалентны размеру градиентов модели, который как уже упоминалось эквивалентен размеру весов модели. 

Так что если мы рассмотрим Adam в качемстве стандартного оптимизиатора, то в памяти лежат $\approx$ веса модели + все посчитанные активации + все градиенты весов + 2 * все градиенты весов.

После первого шага обучения потребление памяти остается на том же уровне, поскольку не добавляется ничего нового и успешно переиспользуется ранняя выделенная память (в предположении, что размер батча зафиксирован).

Таким образом, собирая всё вместе, с использованием Adam необходимо $\approx$ веса модели + все посчитанные активации + все градиенты весов + 2 * все градиенты весов = 4 * веса модели + все посчитанные активации памяти; в терминах типа данных fp32 нам нужно  4 байта * (4 * количество параметров модели + количество элементов в активациях).

# Оптимизации

## Модификации оптимизатора по памяти: Adafactor, 8-bit Adam (автор: Александра Павлова)

## Gradient Accumulation (автор: Азат Валеев)

## Activation Checkpointing (автор: Азат Валеев)

## Mixed Precision (автор: Георгий Ангени)
